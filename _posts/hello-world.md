---
title: "AI Standards and Regulations, Week 13"
excerpt: "
As AI weaves its way into the fabric of our daily lives, its potential to elevate or devastate hangs in the balance. In this post, we're tackling the razor's edge of AI standards and regulations, where the future of our world could be sculpted or shattered by the choices we make today. Let's delve into the pivotal decisions that stand between us and an AI-driven tomorrow."
coverImage: "/assets/blog/hello-world/cover.jpg"
date: "2024-03-25T05:35:07.322Z"
author:
  name: Ilyas Mohamud
  picture: "/assets/blog/authors/ilyas.jpeg"
ogImage:
  url: "/assets/blog/hello-world/cover.jpg"
---

## Introduction to AI Governance

In the realm of artificial intelligence (AI), evaluating models for their capabilities, processing methods, interactions, and responses to various prompts is critical. This encompasses assessing the extent of their access and freedom within operational boundaries. The consensus is clear: governance should be in the hands of those with a deep understanding of the subject. This is predicated on the need for accountability, where regulations play a pivotal role in ensuring responsible AI development and deployment.

## Regulations vs. Standards in AI

### The Necessity for Regulations

The debate between the efficacy of regulations versus standards is crucial in the context of AI governance. While standards have historically guided privacy practices, they have proven inadequate, as evidenced by the breaches of user privacy by corporations. This underscores the indispensability of regulations to enforce accountability, ensuring entities are held responsible for their actions or negligence.

## Developing a Regulatory Mechanism

A proposed regulatory mechanism involves the rigorous evaluation of AI models to prevent the development of unsafe systems. This includes testing models against prompts with malicious intent and assessing their ability to bypass safeguards over a significant period. Despite its merits, this approach may not fully address the problem, hinting at the need for a multifaceted strategy that encompasses various risk reduction techniques.

## Global Approaches to AI Governance

When comparing AI standards and regulations across the US, UK, and China, it's essential to evaluate which provides a solid foundation for mitigating extreme risks. The discussion spans the first two weeks, focusing on each jurisdiction's unique strategies and their effectiveness in addressing AI's challenges.

## Open Source Model Development

The debate on open source model development revolves around its benefits and drawbacks. While open sourcing allows for transparency and collective assurance in the code's safety, it also poses risks of misuse by individuals with malicious intentions. Finding the ideal balance between knowledge sharing and preventing proliferation of harmful uses remains a critical concern.

## Gaps in AI Governance

Current regulations lag behind the ideal vision for AI governance, particularly in the realm of generative AI. There's a pressing need for more comprehensive regulations that specifically address the unique challenges posed by these advanced systems.

## Evaluation and Accountability

The responsibility for evaluating AI systems could either fall to independent organizations, both for-profit and non-profit, or state-employed auditors. Advocating for non-profit organizations emphasizes the importance of unbiased assessments, free from potential conflicts of interest that might influence the evaluation outcome.

## Jurisdictional Feasibility for AI Evaluations

Among the US, UK, EU, and China, the US presents a feasible option for implementing an AI evaluations regime, primarily due to its control over the AI chip supply chain. However, this stance is nuanced by acknowledging the US's self-interest. A more distributed control system could potentially offer a more balanced approach to global AI governance.
